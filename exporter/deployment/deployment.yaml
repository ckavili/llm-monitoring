---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-monitoring
  labels:
    app: llm-monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-monitoring
  template:
    metadata:
      labels:
        app: llm-monitoring
    spec:
      containers:
        - name: llm-monitoring
          image: quay.io/ckavili/llm-monitoring:0.0.1
          imagePullPolicy: Always
          ports:
            - containerPort: 8000
          volumeMounts:
            - name: config-volume
              mountPath: /config/endpoints.json
              subPath: endpoints.json
          resources:
            limits:
              cpu: "500m"
              memory: "256Mi"
            requests:
              cpu: "250m"
              memory: "128Mi"
      volumes:
        - name: config-volume
          configMap:
            name: llm-monitoring-config